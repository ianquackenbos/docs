---
title: Docker Deployment
description: "Deploy Shardly using Docker and Docker Compose"
---

## Overview

Docker Compose is the simplest way to deploy Shardly. Use this deployment method for:

- **Development environments**
- **Small production deployments** (1-10 Elastic Cloud deployments)
- **Proof of concept** and testing

<Warning>
For large production deployments managing 10+ Elasticsearch deployments, use the [Kubernetes deployment](/deployment/kubernetes) instead.
</Warning>

## Prerequisites

Before you begin, ensure you have:

- **Docker** 20.10 or later
- **Docker Compose** 2.0 or later
- **4GB RAM** minimum (8GB recommended for production)
- **20GB disk space** for application and database
- **Network access** to Elastic Cloud API endpoints

<Tip>
On Mac, increase Docker Desktop memory limits in **Settings** → **Resources** → **Memory** to at least 4GB.
</Tip>

## Quick start

<Steps>
<Step title="Clone the repository">
```bash
git clone https://github.com/shardly/shardly.git
cd shardly
```

<Check>
Verify you're in the correct directory: `ls` should show `docker-compose.yml`
</Check>
</Step>

<Step title="Configure environment">
Create your environment file from the template:

```bash
cp .env.example .env
```

Generate a secure encryption key:

```bash
openssl rand -base64 32
```

Edit `.env` with your configuration:

```bash .env
# Database (defaults are fine for Docker Compose)
DATABASE_URL=postgresql://shardly:shardly@postgres:5432/shardly

# Redis (defaults are fine for Docker Compose)
REDIS_URL=redis://redis:6379/0

# Security - paste your generated key here
ENCRYPTION_KEY=dGhpc2lzYXNlY3VyZWVuY3J5cHRpb25rZXk=

# Clerk Authentication (get from https://dashboard.clerk.com)
CLERK_SECRET_KEY=sk_test_xxxxxxxxxxxxx
CLERK_PUBLISHABLE_KEY=pk_test_xxxxxxxxxxxxx
CLERK_WEBHOOK_SECRET=whsec_xxxxxxxxxxxxx

# Anthropic (optional - for AI Copilot feature)
ANTHROPIC_API_KEY=sk-ant-xxxxxxxxxxxxx

# CORS (adjust for your domain)
CORS_ORIGINS=["http://localhost:3000"]
```

<Warning>
Never commit `.env` to version control. It contains sensitive credentials.
</Warning>
</Step>

<Step title="Start all services">
Launch Shardly with Docker Compose:

```bash
docker-compose up -d
```

This starts five containers:
- `shardly-postgres` - PostgreSQL database with TimescaleDB
- `shardly-redis` - Redis for task queue
- `shardly-backend` - FastAPI application
- `shardly-celery` - Background worker
- `shardly-frontend` - Next.js application

Verify all containers are running:

```bash
docker-compose ps
```

Expected output:
```
NAME                STATUS
shardly-postgres    Up
shardly-redis       Up
shardly-backend     Up
shardly-celery      Up
shardly-frontend    Up
```

<Check>
All five containers show "Up" status
</Check>
</Step>

<Step title="Initialize the database">
Run Alembic migrations to create the database schema:

```bash
docker-compose exec backend alembic upgrade head
```

Expected output:
```
INFO  [alembic.runtime.migration] Running upgrade -> 001_initial_schema
INFO  [alembic.runtime.migration] Running upgrade 001 -> head
```

<Check>
Migrations completed without errors
</Check>
</Step>

<Step title="Access Shardly">
Open your browser to these URLs:

- **Frontend Dashboard**: [http://localhost:3000](http://localhost:3000)
- **Backend API**: [http://localhost:8000](http://localhost:8000)
- **API Documentation**: [http://localhost:8000/docs](http://localhost:8000/docs)

<Frame>
<img src="/images/docker-dashboard.png" alt="Shardly dashboard running on localhost:3000 showing the welcome screen" />
</Frame>

<Check>
You can access the dashboard and see the Clerk login page
</Check>
</Step>
</Steps>

## Architecture

```
┌─────────────────────────────────────────────────────────────┐
│                     Docker Network                           │
├─────────────────────────────────────────────────────────────┤
│                                                              │
│  ┌──────────┐  ┌──────────┐  ┌──────────┐  ┌──────────┐    │
│  │ Frontend │  │ Backend  │  │  Worker  │  │  Celery  │    │
│  │  :3000   │  │  :8000   │  │  Celery  │  │   Beat   │    │
│  └────┬─────┘  └────┬─────┘  └────┬─────┘  └────┬─────┘    │
│       │             │             │             │           │
│       │             ▼             ▼             │           │
│       │        ┌─────────────────────────┐      │           │
│       │        │         Redis          │◄─────┘           │
│       │        │         :6379          │                   │
│       │        └─────────────────────────┘                  │
│       │                    │                                │
│       │                    ▼                                │
│       │        ┌─────────────────────────┐                  │
│       └───────►│       PostgreSQL        │                  │
│                │         :5432           │                  │
│                │     (TimescaleDB)       │                  │
│                └─────────────────────────┘                  │
│                                                              │
└─────────────────────────────────────────────────────────────┘
```

## Docker Compose File

```yaml docker-compose.yml
version: '3.8'

services:
  # PostgreSQL with TimescaleDB
  postgres:
    image: timescale/timescaledb:latest-pg15
    environment:
      POSTGRES_USER: shardly
      POSTGRES_PASSWORD: shardly
      POSTGRES_DB: shardly
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U shardly"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Redis
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Backend API
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    environment:
      DATABASE_URL: postgresql://shardly:shardly@postgres:5432/shardly
      REDIS_URL: redis://redis:6379/0
    env_file:
      - .env
    ports:
      - "8000:8000"
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy

  # Celery Worker
  worker:
    build:
      context: ./backend
      dockerfile: Dockerfile
    command: celery -A app.tasks.celery_app worker --loglevel=info
    environment:
      DATABASE_URL: postgresql://shardly:shardly@postgres:5432/shardly
      REDIS_URL: redis://redis:6379/0
    env_file:
      - .env
    depends_on:
      - backend

  # Celery Beat (Scheduler)
  beat:
    build:
      context: ./backend
      dockerfile: Dockerfile
    command: celery -A app.tasks.celery_app beat --loglevel=info
    environment:
      DATABASE_URL: postgresql://shardly:shardly@postgres:5432/shardly
      REDIS_URL: redis://redis:6379/0
    env_file:
      - .env
    depends_on:
      - backend

  # Frontend
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    environment:
      NEXT_PUBLIC_API_URL: http://backend:8000
    env_file:
      - .env
    ports:
      - "3000:3000"
    depends_on:
      - backend

volumes:
  postgres_data:
  redis_data:
```

## Common Operations

### View Logs

```bash
# All services
docker-compose logs -f

# Specific service
docker-compose logs -f backend

# Last 100 lines
docker-compose logs --tail=100 backend
```

### Restart Services

```bash
# Restart all
docker-compose restart

# Restart specific service
docker-compose restart backend
```

### Scale Workers

```bash
# Run 3 worker instances
docker-compose up -d --scale worker=3
```

### Update Images

```bash
# Pull latest images
docker-compose pull

# Rebuild and restart
docker-compose up -d --build
```

### Run Database Migrations

```bash
docker-compose exec backend alembic upgrade head
```

### Access Database

```bash
docker-compose exec postgres psql -U shardly -d shardly
```

### Access Redis

```bash
docker-compose exec redis redis-cli
```

## Health Checks

Check service health:

```bash
# Service status
docker-compose ps

# Health endpoints
curl http://localhost:8000/health
```

## Resource Limits

For production, set resource limits:

```yaml docker-compose.yml
services:
  backend:
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 512M
```

## Networking

### Custom Network

```yaml docker-compose.yml
networks:
  shardly:
    driver: bridge

services:
  backend:
    networks:
      - shardly
```

### External Access

For external access, use a reverse proxy:

```yaml docker-compose.yml
services:
  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
      - ./certs:/etc/nginx/certs
```

## Backup and Restore

### Backup PostgreSQL

```bash
docker-compose exec postgres pg_dump -U shardly shardly > backup.sql
```

### Restore PostgreSQL

```bash
cat backup.sql | docker-compose exec -T postgres psql -U shardly shardly
```

### Backup Volumes

```bash
docker run --rm \
  -v shardly_postgres_data:/data \
  -v $(pwd):/backup \
  alpine tar czf /backup/postgres_backup.tar.gz /data
```

## Troubleshooting

### Container Won't Start

```bash
# Check logs
docker-compose logs backend

# Check configuration
docker-compose config

# Rebuild from scratch
docker-compose down -v
docker-compose up -d --build
```

### Database Connection Failed

```bash
# Verify PostgreSQL is running
docker-compose ps postgres

# Check connectivity
docker-compose exec backend python -c "from app.database import engine; print('OK')"
```

### Out of Memory

```bash
# Check container resources
docker stats

# Increase Docker memory limit in Docker Desktop settings
```

## Production Recommendations

1. **Use managed databases** - AWS RDS, Google Cloud SQL
2. **Use managed Redis** - ElastiCache, Redis Cloud
3. **Enable TLS** - Use a reverse proxy with SSL
4. **Set resource limits** - Prevent runaway containers
5. **Use secrets management** - Don't store secrets in compose file
6. **Enable logging** - Ship logs to centralized logging
7. **Monitor containers** - Use Prometheus, Datadog, etc.

